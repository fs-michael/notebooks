{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Manager Performance on Limited Data using Machine Learning Classification Algorithms\n",
    "\n",
    "In this notebook, we apply various well known Machine Learning algorithms to a dataset of information about 600 managers in an organization to try to predict the performance of the managers.  The purpose of this is to demonstrate that prediction of work-related constructs such as job performance is usually poor across the board due to common inherent issues such as low sample size and poor class distribution.\n",
    "\n",
    "It is common for laypeople in organizations, having read about the power of Machine Learning in other contexts, to believe that it can be applied to the prediction of work related constructs such as job performance.  This example should help demonstrate why this is unlikely to be successful and not a good use of analytic resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load some immediate libraries.  We will load others later as we need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load a dataset directly from Github provided by Keith McNulty.  Note McNulty provided this dataset as an example that could be used to learn explanatory analytic methods, not predictive methods.  This exercise will demonstrate the shortcoming of predictive methods on data of this nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_data = pd.read_csv('https://raw.githubusercontent.com/keithmcnulty/ebp_exercise/master/data.csv', \n",
    "                           index_col = 'employee_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a brief look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 571 entries, c4578853 to e81f635b\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   performance_group  571 non-null    object \n",
      " 1   yrs_employed       571 non-null    float64\n",
      " 2   manager_hire       571 non-null    object \n",
      " 3   test_score         571 non-null    int64  \n",
      " 4   group_size         571 non-null    int64  \n",
      " 5   concern_flag       571 non-null    object \n",
      " 6   mobile_flag        571 non-null    object \n",
      " 7   customers          571 non-null    int64  \n",
      " 8   high_hours_flag    571 non-null    object \n",
      " 9   transfers          571 non-null    int64  \n",
      " 10  reduced_schedule   571 non-null    object \n",
      " 11  city               571 non-null    object \n",
      "dtypes: float64(1), int64(4), object(7)\n",
      "memory usage: 58.0+ KB\n"
     ]
    }
   ],
   "source": [
    "manager_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performance_group</th>\n",
       "      <th>yrs_employed</th>\n",
       "      <th>manager_hire</th>\n",
       "      <th>test_score</th>\n",
       "      <th>group_size</th>\n",
       "      <th>concern_flag</th>\n",
       "      <th>mobile_flag</th>\n",
       "      <th>customers</th>\n",
       "      <th>high_hours_flag</th>\n",
       "      <th>transfers</th>\n",
       "      <th>reduced_schedule</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c4578853</th>\n",
       "      <td>Bottom</td>\n",
       "      <td>4.6</td>\n",
       "      <td>N</td>\n",
       "      <td>205</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a7d7afd6</th>\n",
       "      <td>Middle</td>\n",
       "      <td>5.3</td>\n",
       "      <td>N</td>\n",
       "      <td>227</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272b93f1</th>\n",
       "      <td>Bottom</td>\n",
       "      <td>5.2</td>\n",
       "      <td>N</td>\n",
       "      <td>227</td>\n",
       "      <td>10</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be8b6baa</th>\n",
       "      <td>Middle</td>\n",
       "      <td>4.9</td>\n",
       "      <td>N</td>\n",
       "      <td>273</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>26</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a18ecc4e</th>\n",
       "      <td>Bottom</td>\n",
       "      <td>4.9</td>\n",
       "      <td>N</td>\n",
       "      <td>227</td>\n",
       "      <td>17</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>26</td>\n",
       "      <td>Y</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>Orlando</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            performance_group  yrs_employed manager_hire  test_score  \\\n",
       "employee_id                                                            \n",
       "c4578853               Bottom           4.6            N         205   \n",
       "a7d7afd6               Middle           5.3            N         227   \n",
       "272b93f1               Bottom           5.2            N         227   \n",
       "be8b6baa               Middle           4.9            N         273   \n",
       "a18ecc4e               Bottom           4.9            N         227   \n",
       "\n",
       "             group_size concern_flag mobile_flag  customers high_hours_flag  \\\n",
       "employee_id                                                                   \n",
       "c4578853             10            N           N         12               N   \n",
       "a7d7afd6             14            N           Y         18               N   \n",
       "272b93f1             10            N           N         12               N   \n",
       "be8b6baa             19            N           N         26               Y   \n",
       "a18ecc4e             17            Y           N         26               Y   \n",
       "\n",
       "             transfers reduced_schedule           city  \n",
       "employee_id                                             \n",
       "c4578853             0                Y  San Francisco  \n",
       "a7d7afd6             0                N       New York  \n",
       "272b93f1             0                Y        Chicago  \n",
       "be8b6baa             0                N       New York  \n",
       "a18ecc4e             5                Y        Orlando  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the data consists of 571 observations of managers, with numeric and categorical features, and is to some extent pre-processed.  If you would like to understand the features better, see [McNulty's repo](https://github.com/keithmcnulty/ebp_exercise).\n",
    "\n",
    "`performance_group` is the field that we will be trying to predict.  Let's take a quick look at its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='performance_group', ylabel='count'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = manager_data, x = \"performance_group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have three performance categories, and as is typical with human ratings, there is a considerable degree of central tendency bias with around two-thirds of all ratings taking the middle category.\n",
    "\n",
    "To keep our classification problem simple, let's choose to predict one category.  In any Machine Learning problem, class imbalance can cause a challenge, and so for this reason lets choose to predict the Bottom performers.  Approximately 20% of the sample will therefore be in the positive class, and about 80% will be in the negative class.  Algorithms will learn quickly that, all else being equal, predicting negative will give the best chance of success, therefore we will be interested in algorithm that are 'braver' and more successful in predicting the minority of positive classes.\n",
    "\n",
    "Let's transform our data so that our target is a simple binary classification of 'Bottom' or 'Not Bottom'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to binary bottom\n",
    "binary_bottom = pd.get_dummies(manager_data['performance_group'])['Bottom']\n",
    "binary_bottom.columns = 'Bottom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_data_bot = pd.concat([manager_data.drop('performance_group', axis = 1), binary_bottom], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a number of our input features are categorical, so we will need to transform these into dummy variables for learning purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get dummies\n",
    "dummy_vars = ['manager_hire', 'concern_flag', \n",
    "             'mobile_flag', 'high_hours_flag', \n",
    "             'reduced_schedule', 'city']\n",
    "\n",
    "dummies = pd.get_dummies(manager_data_bot[dummy_vars], \n",
    "                         drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([manager_data_bot.drop(dummy_vars, axis = 1), dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have transformed our data to prepare for the learning process, let's split it into an object for inputs and an object for outputs, and take a quick look at these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yrs_employed</th>\n",
       "      <th>test_score</th>\n",
       "      <th>group_size</th>\n",
       "      <th>customers</th>\n",
       "      <th>transfers</th>\n",
       "      <th>manager_hire_Y</th>\n",
       "      <th>concern_flag_Y</th>\n",
       "      <th>mobile_flag_Y</th>\n",
       "      <th>high_hours_flag_Y</th>\n",
       "      <th>reduced_schedule_Y</th>\n",
       "      <th>city_Houston</th>\n",
       "      <th>city_New York</th>\n",
       "      <th>city_Orlando</th>\n",
       "      <th>city_San Francisco</th>\n",
       "      <th>city_Toronto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c4578853</th>\n",
       "      <td>4.6</td>\n",
       "      <td>205</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a7d7afd6</th>\n",
       "      <td>5.3</td>\n",
       "      <td>227</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272b93f1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>227</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be8b6baa</th>\n",
       "      <td>4.9</td>\n",
       "      <td>273</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a18ecc4e</th>\n",
       "      <td>4.9</td>\n",
       "      <td>227</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             yrs_employed  test_score  group_size  customers  transfers  \\\n",
       "employee_id                                                               \n",
       "c4578853              4.6         205          10         12          0   \n",
       "a7d7afd6              5.3         227          14         18          0   \n",
       "272b93f1              5.2         227          10         12          0   \n",
       "be8b6baa              4.9         273          19         26          0   \n",
       "a18ecc4e              4.9         227          17         26          5   \n",
       "\n",
       "             manager_hire_Y  concern_flag_Y  mobile_flag_Y  high_hours_flag_Y  \\\n",
       "employee_id                                                                     \n",
       "c4578853                  0               0              0                  0   \n",
       "a7d7afd6                  0               0              1                  0   \n",
       "272b93f1                  0               0              0                  0   \n",
       "be8b6baa                  0               0              0                  1   \n",
       "a18ecc4e                  0               1              0                  1   \n",
       "\n",
       "             reduced_schedule_Y  city_Houston  city_New York  city_Orlando  \\\n",
       "employee_id                                                                  \n",
       "c4578853                      1             0              0             0   \n",
       "a7d7afd6                      0             0              1             0   \n",
       "272b93f1                      1             0              0             0   \n",
       "be8b6baa                      0             0              1             0   \n",
       "a18ecc4e                      1             0              0             1   \n",
       "\n",
       "             city_San Francisco  city_Toronto  \n",
       "employee_id                                    \n",
       "c4578853                      1             0  \n",
       "a7d7afd6                      0             0  \n",
       "272b93f1                      0             0  \n",
       "be8b6baa                      0             0  \n",
       "a18ecc4e                      0             0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('Bottom', axis = 1)\n",
    "y = data['Bottom']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id\n",
       "c4578853    1\n",
       "a7d7afd6    0\n",
       "272b93f1    1\n",
       "be8b6baa    0\n",
       "a18ecc4e    1\n",
       "Name: Bottom, dtype: uint8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features and our target look good.  So we can proceed.  First we will try to use a simple logistic regression model to predict Bottom performers.\n",
    "\n",
    "## Logistic Regression Model\n",
    "\n",
    "For more on the mathematics underlying Logistic Regression, see Section 4.3 of [An Introduction to Statistical Learning](https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf).  \n",
    "\n",
    "We import our model, and divide our sets into training and testing sets using a 70/30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create and fit a model to the training data.  Note that for Logistic Regression model we do not need to worry about scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our fitted model to predict the performance of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the predicted performance of the test set to the actual performance and generate a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128   2]\n",
      " [ 40   2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is very shy to predict anyone in the Bottom performance group. The right hand colum tells us that of the four people it did predict to be Bottom performance, two of them were Bottom performers.  However there were forty other Bottom performers that it did not predict correctly.\n",
    "\n",
    "Let's look at a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       130\n",
      "           1       0.50      0.05      0.09        42\n",
      "\n",
      "    accuracy                           0.76       172\n",
      "   macro avg       0.63      0.52      0.47       172\n",
      "weighted avg       0.70      0.76      0.67       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `f1-score` is a particularly valuable metric in situations like these of class imbalance.  We see a much better F1 for the prediction of the negative class - which is of course easy to predict by chance because 80% of the sample are in the negative class.  If our prime interest is predicting the positive class, this model performs very poorly.\n",
    "\n",
    "## K-Nearest Neighbours \n",
    "\n",
    "We will now try to predict Bottom performers by using an algorithm that tries to identify people with similar features and predict on the basis of how many of those are Bottom performers.  For more on the mathematics underlying K Nearest Neighbours, see page 39 of An Introduction to Statistical Learning.\n",
    "\n",
    "For subsequent methods we will need to scale our input data, which we will do using a Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need to find the best value of K, and we can do this using the elbow method.  We try several consecutive values of K and calculate the prediction error for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "for i in range(1, 40):\n",
    "    modeli = KNeighborsClassifier(n_neighbors=i)\n",
    "    modeli.fit(X_train, y_train)\n",
    "    predicti = modeli.predict(X_test)\n",
    "    error_rate.append(np.mean(predicti != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = pd.DataFrame(dict(k=range(1,40), err=error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='k', ylabel='err'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data = error_rate, x = 'k', y = 'err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 6 look like an early error minimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnmodel = KNeighborsClassifier(n_neighbors=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit and measure our model as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=6)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnpredicts = knnmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126   4]\n",
      " [ 37   5]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, knnpredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is a bit braver compared to our Logistic Regression model.  It suggests nine people as Bottom performers and is accurate for more than half.  It still misses 37 of them though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86       130\n",
      "           1       0.56      0.12      0.20        42\n",
      "\n",
      "    accuracy                           0.76       172\n",
      "   macro avg       0.66      0.54      0.53       172\n",
      "weighted avg       0.72      0.76      0.70       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knnpredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is a better performing classifies compared to Logistic Regression, it is still quite poor.\n",
    "\n",
    "## Basic Decision Tree\n",
    "\n",
    "We will now apply a Decision Tree model to our data.  For more on Decision Trees see Section 8.1 of An Introduction to Statistical Learning.\n",
    "\n",
    "We will take an identical approach by setting up our model, fitting it and measuring the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treemodel = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treemodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "treepredicts = treemodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  30]\n",
      " [ 30  12]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, treepredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is much happier to classify positive classes, identfiying 42 individuals as being potential Bottom performers.  However it is accurate in less than 30% of them.  Nevertheless if you are only concerned with getting the largest number of accurate predictions of Bottom performers, this algorithm performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       130\n",
      "           1       0.29      0.29      0.29        42\n",
      "\n",
      "    accuracy                           0.65       172\n",
      "   macro avg       0.53      0.53      0.53       172\n",
      "weighted avg       0.65      0.65      0.65       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, treepredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report confirms that this model performs better at finding Bottom performers. \n",
    "\n",
    "## Random Forest \n",
    "\n",
    "Random Forest algorithms construct numerous decision trees and output the mode of the classes from each.  For more information, see Section 8.2 of An Introduction to Statistical Learning. \n",
    "\n",
    "Given the imbalance in this dataset, splitting it into too many trees will only serve to increase the bias to classify inputs as negative.  We could try with a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forestmodel = RandomForestClassifier(n_estimators = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestpredicts = forestmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  25]\n",
      " [ 26  16]]\n"
     ]
    }
   ],
   "source": [
    "print((confusion_matrix(y_test, forestpredicts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly it predicts more than the Basic Decision Tree and has a better hit rate.  If you experiment with greater numbers of trees you will find that it starts to bias heavily towards negative classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80       130\n",
      "           1       0.39      0.38      0.39        42\n",
      "\n",
      "    accuracy                           0.70       172\n",
      "   macro avg       0.60      0.59      0.60       172\n",
      "weighted avg       0.70      0.70      0.70       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((classification_report(y_test, forestpredicts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this is our best performing algorithm for identifying Bottom performers.  Still, it's wrong more than it's right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "We will now try a different type of classifier which uses linear algebra to plot each input in n-dimensional space and tries to find a 'separating hyperplane' to use to classify the data.  You can read more about this in Chapter 9 of An Introduction to Statistical Learning.\n",
    "\n",
    "The best performance I could find from the Support Vector Classifier was where it used a 5th degree polynomial as its kernel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmmodel = SVC(kernel='poly', degree = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=5, kernel='poly')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpredicts = svmmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122   8]\n",
      " [ 33   9]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, svmpredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model selected 17 Bottom performers and was correct in more than half.  Overall this performance is not as good as the prior Random Forest classifier, if your objective is the identification of Bottom performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       130\n",
      "           1       0.53      0.21      0.31        42\n",
      "\n",
      "    accuracy                           0.76       172\n",
      "   macro avg       0.66      0.58      0.58       172\n",
      "weighted avg       0.72      0.76      0.72       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((classification_report(y_test, svmpredicts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Artificial Neural Network\n",
    "\n",
    "An Artificial Neural Network is really suited to complex learning tasks with large amounts of data.  It is very unlikely to be effective on such a small and chaotic dataset and will be very dificult not to overfit.  Nevertheless I include it here for reference.  \n",
    "\n",
    "We use Tensorflow and Keras to train a simple Neural Network with an one hidden Dense layer, using fairly standard relu activation functions.  I didn't spend time parameter tuning here, as it wouldn't be worth the effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "annmodel = Sequential()\n",
    "\n",
    "# input layer\n",
    "annmodel.add(Dense(15, activation='relu'))\n",
    "\n",
    "\n",
    "# hidden layer\n",
    "annmodel.add(Dense(5, activation='relu'))\n",
    "\n",
    "\n",
    "# output layer\n",
    "annmodel.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "annmodel.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1.6125 - val_loss: 1.9758\n",
      "Epoch 2/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3376 - val_loss: 1.6017\n",
      "Epoch 3/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.1804 - val_loss: 1.5554\n",
      "Epoch 4/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1187 - val_loss: 1.5306\n",
      "Epoch 5/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0997 - val_loss: 1.5164\n",
      "Epoch 6/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0864 - val_loss: 1.5062\n",
      "Epoch 7/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0756 - val_loss: 1.4947\n",
      "Epoch 8/25\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 1.0666 - val_loss: 1.4871\n",
      "Epoch 9/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0571 - val_loss: 1.4785\n",
      "Epoch 10/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0488 - val_loss: 1.4736\n",
      "Epoch 11/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0409 - val_loss: 1.4692\n",
      "Epoch 12/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0357 - val_loss: 1.4647\n",
      "Epoch 13/25\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 1.0289 - val_loss: 1.3991\n",
      "Epoch 14/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0229 - val_loss: 1.4703\n",
      "Epoch 15/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0182 - val_loss: 1.5244\n",
      "Epoch 16/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0126 - val_loss: 1.5186\n",
      "Epoch 17/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0083 - val_loss: 1.5203\n",
      "Epoch 18/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0038 - val_loss: 1.5185\n",
      "Epoch 19/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.0008 - val_loss: 1.5781\n",
      "Epoch 20/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.9959 - val_loss: 1.5704\n",
      "Epoch 21/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.9918 - val_loss: 1.5683\n",
      "Epoch 22/25\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9880 - val_loss: 1.5646\n",
      "Epoch 23/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.9841 - val_loss: 1.5616\n",
      "Epoch 24/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.9804 - val_loss: 1.5592\n",
      "Epoch 25/25\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.9776 - val_loss: 1.5548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f9322e520>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annmodel.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=25,\n",
    "          validation_data=(X_test, y_test) \n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-247-b3d3e546df17>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "annpredicts = annmodel.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125   5]\n",
      " [ 39   3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, annpredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this did not perform well, and most likely overfit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85       130\n",
      "           1       0.38      0.07      0.12        42\n",
      "\n",
      "    accuracy                           0.74       172\n",
      "   macro avg       0.57      0.52      0.49       172\n",
      "weighted avg       0.67      0.74      0.67       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, annpredicts ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Finally, we will use an XGBoost classifier which is a fairly novel, gradient boosted improvement on Decision Tree classifiers which has gotten a lot of attention and positive review from the ML community.  Similar to Random Forest, I also found that using a single tree (estimator) produced the best results in my opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = XGBClassifier(n_estimators = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbpredicts = xgbmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120  10]\n",
      " [ 31  11]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, xgbpredicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       130\n",
      "           1       0.52      0.26      0.35        42\n",
      "\n",
      "    accuracy                           0.76       172\n",
      "   macro avg       0.66      0.59      0.60       172\n",
      "weighted avg       0.73      0.76      0.73       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgbpredicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be argued that this algorithm is the best of a bad bunch, because it has a good balance in F1 score between the negative and positive classes.  However, it is not as good as our Random Forest model in identifying Bottom performers.  \n",
    "\n",
    "Of course, it's not the algorithms that are bad, it's the data. In general data on individuals in a workplace setting suffers from a number of issues, not least "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
